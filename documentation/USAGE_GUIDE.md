# Haystack Usage Guide (‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Haystack)

## üéØ ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

1. [‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤](#‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤)
2. [‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô](#‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô)
3. [‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Component ‡πÅ‡∏£‡∏Å](#‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á-component-‡πÅ‡∏£‡∏Å)
4. [‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline](#‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á-pipeline)
5. [‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Documents](#‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö-documents)
6. [‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö RAG](#‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö-rag)
7. [‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LLM](#‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô-llm)
8. [‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö](#‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö)
9. [‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á](#‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á)
10. [‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤](#‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤)

---

## ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

### üîß ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Haystack
pip install haystack-ai

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤
pip install -e .
pip install hatch
python -m hatch env create test
```

### üåê ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Keys

```bash
# OpenAI
export OPENAI_API_KEY="your-api-key-here"

# Cohere
export COHERE_API_KEY="your-api-key-here"

# HuggingFace
export HUGGINGFACE_API_TOKEN="your-token-here"
```

### ‚úÖ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

```python
import haystack
print(f"Haystack version: {haystack.__version__}")

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö import ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
from haystack import component, Pipeline, Document
print("‚úÖ Haystack ready to use!")
```

---

## ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

### üß© Components
**Components** ‡∏Ñ‡∏∑‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÉ‡∏ô Haystack:
- ‡∏£‡∏±‡∏ö input ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á output
- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô pipeline ‡πÑ‡∏î‡πâ
- ‡∏°‡∏µ built-in components ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏≠‡∏á‡πÑ‡∏î‡πâ

### üîó Pipelines
**Pipelines** ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ components ‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô:
- ‡∏Å‡∏≥‡∏´‡∏ô‡∏î flow ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
- ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á components
- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏°‡∏µ branches ‡πÅ‡∏•‡∏∞ loops ‡πÑ‡∏î‡πâ

### üìÑ Documents
**Documents** ‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:
- ‡∏°‡∏µ content ‡πÅ‡∏•‡∏∞ metadata
- ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÑ‡∏î‡πâ

---

## ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Component ‡πÅ‡∏£‡∏Å

### üìù Component ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

```python
from haystack import component

@component
class TextProcessor:
    @component.output_types(processed_text=str, word_count=int)
    def run(self, text: str) -> dict:
        processed = text.strip().upper()
        word_count = len(text.split())
        
        return {
            "processed_text": processed,
            "word_count": word_count
        }

# ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
processor = TextProcessor()
result = processor.run(text="hello world")
print(result)  # {'processed_text': 'HELLO WORLD', 'word_count': 2}
```

### üéõÔ∏è Component ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ Configuration

```python
@component
class CustomAnalyzer:
    def __init__(self, min_word_length: int = 3, case_sensitive: bool = False):
        self.min_word_length = min_word_length
        self.case_sensitive = case_sensitive
    
    @component.output_types(filtered_words=list, stats=dict)
    def run(self, text: str) -> dict:
        words = text.split()
        if not self.case_sensitive:
            words = [w.lower() for w in words]
        
        filtered = [w for w in words if len(w) >= self.min_word_length]
        
        return {
            "filtered_words": filtered,
            "stats": {
                "total_words": len(words),
                "filtered_words": len(filtered),
                "average_length": sum(len(w) for w in filtered) / len(filtered) if filtered else 0
            }
        }
```

### üîÑ Async Component

```python
import asyncio

@component
class AsyncProcessor:
    @component.output_types(result=str)
    async def run(self, text: str, delay: float = 1.0) -> dict:
        await asyncio.sleep(delay)
        return {"result": f"Processed after {delay}s: {text}"}
```

---

## ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Pipeline

### üöá Pipeline ‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á

```python
from haystack import Pipeline

# ‡∏™‡∏£‡πâ‡∏≤‡∏á components
processor = TextProcessor()
analyzer = CustomAnalyzer(min_word_length=4)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á pipeline
pipeline = Pipeline()
pipeline.add_component("processor", processor)
pipeline.add_component("analyzer", analyzer)

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ components
pipeline.connect("processor.processed_text", "analyzer.text")

# ‡∏£‡∏±‡∏ô pipeline
result = pipeline.run({
    "processor": {"text": "Hello wonderful world of programming"}
})

print(result["analyzer"]["filtered_words"])
```

### üîÄ Pipeline ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ Branches

```python
@component
class Router:
    @component.output_types(short_text=str, long_text=str)
    def run(self, text: str, threshold: int = 50) -> dict:
        if len(text) <= threshold:
            return {"short_text": text, "long_text": ""}
        else:
            return {"short_text": "", "long_text": text}

@component 
class ShortTextHandler:
    @component.output_types(result=str)
    def run(self, text: str) -> dict:
        return {"result": f"Short: {text.upper()}"}

@component
class LongTextHandler:
    @component.output_types(result=str)
    def run(self, text: str) -> dict:
        return {"result": f"Long: {text[:20]}..."}

# ‡∏™‡∏£‡πâ‡∏≤‡∏á branched pipeline
pipeline = Pipeline()
pipeline.add_component("router", Router())
pipeline.add_component("short_handler", ShortTextHandler())
pipeline.add_component("long_handler", LongTextHandler())

pipeline.connect("router.short_text", "short_handler.text")
pipeline.connect("router.long_text", "long_handler.text")
```

### üîÑ Pipeline ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ Loop

```python
@component
class IterativeImprover:
    @component.output_types(improved_text=str, should_continue=bool)
    def run(self, text: str, iteration: int = 0, max_iterations: int = 3) -> dict:
        # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
        improved = text.replace("  ", " ").strip()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏ï‡πà‡∏≠‡πÑ‡∏´‡∏°
        should_continue = iteration < max_iterations and "  " in text
        
        return {
            "improved_text": improved,
            "should_continue": should_continue
        }

# Pipeline ‡∏ó‡∏µ‡πà‡∏°‡∏µ feedback loop
pipeline = Pipeline()
pipeline.add_component("improver", IterativeImprover())
# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ output ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö loop
pipeline.connect("improver.improved_text", "improver.text")
```

---

## ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Documents

### üìÑ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Documents

```python
from haystack import Document

# ‡∏™‡∏£‡πâ‡∏≤‡∏á document ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
doc1 = Document(
    content="Haystack is an amazing framework for building search systems.",
    meta={"source": "documentation", "category": "technical"}
)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á document ‡∏à‡∏≤‡∏Å dictionary
doc_data = {
    "content": "Machine learning revolutionizes data processing.",
    "meta": {"author": "AI Expert", "date": "2024-01-15"}
}
doc2 = Document(**doc_data)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á document list
documents = [doc1, doc2]
print(f"Created {len(documents)} documents")
```

### üîß ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Documents

```python
from haystack.components.preprocessors import DocumentSplitter

# ‡πÅ‡∏¢‡∏Å documents ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏•‡πá‡∏Å
splitter = DocumentSplitter(
    split_by="word",      # ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥
    split_length=50,      # 50 ‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡∏™‡πà‡∏ß‡∏ô
    split_overlap=10      # overlap 10 ‡∏Ñ‡∏≥
)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• documents
doc_pipeline = Pipeline()
doc_pipeline.add_component("splitter", splitter)

result = doc_pipeline.run({
    "splitter": {"documents": documents}
})

split_docs = result["splitter"]["documents"]
print(f"Split into {len(split_docs)} chunks")
```

### üóÑÔ∏è ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö Documents

```python
from haystack.document_stores.in_memory import InMemoryDocumentStore
from haystack.components.writers import DocumentWriter

# ‡∏™‡∏£‡πâ‡∏≤‡∏á document store
document_store = InMemoryDocumentStore()

# ‡∏™‡∏£‡πâ‡∏≤‡∏á writer component
writer = DocumentWriter(document_store=document_store)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á indexing pipeline
indexing_pipeline = Pipeline()
indexing_pipeline.add_component("splitter", splitter)
indexing_pipeline.add_component("writer", writer)
indexing_pipeline.connect("splitter", "writer")

# Index documents
result = indexing_pipeline.run({
    "splitter": {"documents": documents}
})

print(f"Indexed {result['writer']['documents_written']} documents")
```

---

## ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö RAG

### üîç Retrieval (‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤)

```python
from haystack.components.retrievers.in_memory import InMemoryBM25Retriever

# ‡∏™‡∏£‡πâ‡∏≤‡∏á retriever
retriever = InMemoryBM25Retriever(document_store=document_store)

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
search_pipeline = Pipeline()
search_pipeline.add_component("retriever", retriever)

search_result = search_pipeline.run({
    "retriever": {
        "query": "machine learning framework",
        "top_k": 3
    }
})

retrieved_docs = search_result["retriever"]["documents"]
for i, doc in enumerate(retrieved_docs):
    print(f"{i+1}. Score: {doc.score:.3f}")
    print(f"   Content: {doc.content[:100]}...")
```

### üìù Generation (‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö)

```python
from haystack.components.builders import PromptBuilder
from haystack.components.generators import OpenAIGenerator

# ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt template
template = """
Based on the following context, answer the question.

Context:
{% for doc in documents %}
{{ doc.content }}
{% endfor %}

Question: {{ question }}

Answer:
"""

# ‡∏™‡∏£‡πâ‡∏≤‡∏á components
prompt_builder = PromptBuilder(template=template)
generator = OpenAIGenerator(
    model="gpt-3.5-turbo-instruct",
    generation_kwargs={"max_tokens": 200}
)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á RAG pipeline
rag_pipeline = Pipeline()
rag_pipeline.add_component("retriever", retriever)
rag_pipeline.add_component("prompt_builder", prompt_builder)
rag_pipeline.add_component("generator", generator)

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ components
rag_pipeline.connect("retriever.documents", "prompt_builder.documents")
rag_pipeline.connect("prompt_builder.prompt", "generator.prompt")
```

### ü§ñ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô RAG Pipeline

```python
def ask_question(question: str, top_k: int = 3):
    """‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ú‡πà‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö RAG"""
    
    if not os.getenv("OPENAI_API_KEY"):
        print("‚ùå OPENAI_API_KEY not set")
        return None
    
    try:
        result = rag_pipeline.run({
            "retriever": {
                "query": question,
                "top_k": top_k
            },
            "prompt_builder": {
                "question": question
            }
        })
        
        answer = result["generator"]["replies"][0]
        retrieved_docs = result["retriever"]["documents"]
        
        print(f"‚ùì Question: {question}")
        print(f"‚úÖ Answer: {answer}")
        print(f"üìö Based on {len(retrieved_docs)} documents")
        
        return answer
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return None

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö
ask_question("What is Haystack used for?")
ask_question("How does machine learning work?")
```

---

## ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô LLM

### üéØ Chat-based Generation

```python
from haystack.components.generators import OpenAIChatGenerator
from haystack.dataclasses import ChatMessage

# ‡∏™‡∏£‡πâ‡∏≤‡∏á chat generator
chat_generator = OpenAIChatGenerator(
    model="gpt-3.5-turbo",
    generation_kwargs={"temperature": 0.7}
)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á chat messages
messages = [
    ChatMessage.from_system("You are a helpful AI assistant specialized in explaining technical concepts."),
    ChatMessage.from_user("Explain how neural networks work in simple terms.")
]

# ‡∏™‡∏£‡πâ‡∏≤‡∏á chat pipeline
chat_pipeline = Pipeline()
chat_pipeline.add_component("chat_generator", chat_generator)

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
result = chat_pipeline.run({
    "chat_generator": {"messages": messages}
})

response = result["chat_generator"]["replies"][0]
print(response.content)
```

### üõ†Ô∏è Custom LLM Wrapper

```python
@component
class CustomLLMWrapper:
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        self.model_name = model_name
        
    @component.output_types(reply=str, metadata=dict)
    def run(
        self, 
        prompt: str, 
        temperature: float = 0.7,
        max_tokens: int = 100
    ) -> dict:
        """Custom LLM wrapper with additional processing"""
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° context ‡πÅ‡∏•‡∏∞ formatting
        enhanced_prompt = f"""
        Context: You are an expert assistant.
        
        User Query: {prompt}
        
        Instructions: Provide a clear and concise answer.
        
        Response:
        """
        
        try:
            # ‡πÉ‡∏ä‡πâ OpenAI (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ API key)
            from openai import OpenAI
            client = OpenAI()
            
            response = client.completions.create(
                model="gpt-3.5-turbo-instruct",
                prompt=enhanced_prompt,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            reply = response.choices[0].text.strip()
            metadata = {
                "model": self.model_name,
                "tokens_used": response.usage.total_tokens,
                "temperature": temperature
            }
            
            return {"reply": reply, "metadata": metadata}
            
        except Exception as e:
            return {
                "reply": f"Error: {str(e)}",
                "metadata": {"error": True}
            }
```

---

## ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

### üß™ Unit Testing Components

```python
import pytest
from haystack import component

@component
class SimpleAdder:
    @component.output_types(result=int)
    def run(self, a: int, b: int) -> dict:
        return {"result": a + b}

def test_simple_adder():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö component ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô"""
    adder = SimpleAdder()
    result = adder.run(a=5, b=3)
    
    assert result["result"] == 8
    assert isinstance(result["result"], int)

def test_simple_adder_negative():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏•‡∏Ç‡∏•‡∏ö"""
    adder = SimpleAdder()
    result = adder.run(a=-5, b=3)
    
    assert result["result"] == -2

# ‡∏£‡∏±‡∏ô‡πÄ‡∏ó‡∏™‡∏ï‡πå
# python -m pytest test_components.py -v
```

### üîó Testing Pipelines

```python
def test_text_processing_pipeline():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö pipeline ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå"""
    processor = TextProcessor()
    analyzer = CustomAnalyzer(min_word_length=3)
    
    pipeline = Pipeline()
    pipeline.add_component("processor", processor)
    pipeline.add_component("analyzer", analyzer)
    pipeline.connect("processor.processed_text", "analyzer.text")
    
    result = pipeline.run({
        "processor": {"text": "hello world"}
    })
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    assert "analyzer" in result
    assert "filtered_words" in result["analyzer"]
    assert len(result["analyzer"]["filtered_words"]) >= 0

@pytest.mark.integration
def test_rag_pipeline_integration():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö RAG pipeline (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ API key)"""
    if not os.getenv("OPENAI_API_KEY"):
        pytest.skip("OPENAI_API_KEY not set")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö RAG pipeline
    documents = [Document(content="Test content about AI")]
    
    # TODO: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö RAG pipeline
    assert True  # placeholder
```

### üìä ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÄ‡∏ó‡∏™‡∏ï‡πå

```bash
# ‡∏£‡∏±‡∏ô‡πÄ‡∏ó‡∏™‡∏ï‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
python -m hatch run test:unit

# ‡∏£‡∏±‡∏ô‡πÄ‡∏ó‡∏™‡∏ï‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÑ‡∏ü‡∏•‡πå
python -m hatch run test:pytest test_components.py -v

# ‡∏£‡∏±‡∏ô‡πÄ‡∏ó‡∏™‡∏ï‡πå integration
python -m hatch run test:integration

# ‡∏£‡∏±‡∏ô‡πÄ‡∏ó‡∏™‡∏ï‡πå‡∏û‡∏£‡πâ‡∏≠‡∏° coverage
python -m hatch run test:pytest --cov=haystack --cov-report=html
```

---

## ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á

### üîß Custom Document Store

```python
from haystack.document_stores.types import DocumentStore
from typing import List, Optional

class CustomDocumentStore(DocumentStore):
    """Custom document store implementation"""
    
    def __init__(self):
        self.documents = {}
        self.next_id = 1
    
    def write_documents(self, documents: List[Document]) -> int:
        """‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô documents ‡∏•‡∏á store"""
        written = 0
        for doc in documents:
            if not doc.id:
                doc.id = str(self.next_id)
                self.next_id += 1
            self.documents[doc.id] = doc
            written += 1
        return written
    
    def filter_documents(self, filters: Optional[dict] = None) -> List[Document]:
        """‡∏Å‡∏£‡∏≠‡∏á documents ‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç"""
        docs = list(self.documents.values())
        
        if filters:
            # ‡πÉ‡∏ä‡πâ logic ‡∏Å‡∏£‡∏≠‡∏á‡∏ï‡∏≤‡∏° filters
            pass
            
        return docs
    
    def delete_documents(self, document_ids: List[str]) -> None:
        """‡∏•‡∏ö documents"""
        for doc_id in document_ids:
            self.documents.pop(doc_id, None)
```

### üéõÔ∏è Pipeline Configuration

```python
# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å pipeline configuration
pipeline_config = {
    "components": {
        "retriever": {
            "type": "InMemoryBM25Retriever",
            "init_parameters": {
                "document_store": {"type": "InMemoryDocumentStore"}
            }
        },
        "prompt_builder": {
            "type": "PromptBuilder", 
            "init_parameters": {
                "template": "Context: {{documents}}\nQuestion: {{question}}\nAnswer:"
            }
        }
    },
    "connections": [
        {"sender": "retriever.documents", "receiver": "prompt_builder.documents"}
    ]
}

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå
import json
with open("pipeline_config.json", "w") as f:
    json.dump(pipeline_config, f, indent=2)
```

### üöÄ Performance Optimization

```python
@component
class CachedRetriever:
    """Retriever ‡∏û‡∏£‡πâ‡∏≠‡∏° caching"""
    
    def __init__(self, base_retriever, cache_size: int = 1000):
        self.base_retriever = base_retriever
        self.cache = {}
        self.cache_size = cache_size
    
    @component.output_types(documents=List[Document])
    def run(self, query: str, top_k: int = 10) -> dict:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö cache
        cache_key = f"{query}:{top_k}"
        if cache_key in self.cache:
            return {"documents": self.cache[cache_key]}
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏£‡∏¥‡∏á
        result = self.base_retriever.run(query=query, top_k=top_k)
        documents = result["documents"]
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á cache
        if len(self.cache) >= self.cache_size:
            # ‡∏•‡∏ö entry ‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏∏‡∏î
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        self.cache[cache_key] = documents
        return {"documents": documents}

# ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Async Pipeline
from haystack.core.pipeline import AsyncPipeline

async def run_async_pipeline():
    """‡∏£‡∏±‡∏ô pipeline ‡πÅ‡∏ö‡∏ö async"""
    pipeline = AsyncPipeline()
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° async components
    async_processor = AsyncProcessor()
    pipeline.add_component("processor", async_processor)
    
    result = await pipeline.run({
        "processor": {"text": "Hello async world", "delay": 0.5}
    })
    
    return result
```

---

## ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤

### üêõ ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢

#### 1. Import Errors
```bash
# ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ModuleNotFoundError
‚ùå ModuleNotFoundError: No module named 'haystack'

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
pip install haystack-ai
# ‡∏´‡∏£‡∏∑‡∏≠
pip install -e .
```

#### 2. API Key Issues
```bash
# ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: API key ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
‚ùå InvalidAPIKey: Invalid API key provided

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
export OPENAI_API_KEY="sk-your-actual-key-here"
echo $OPENAI_API_KEY  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
```

#### 3. Pipeline Connection Errors
```python
# ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ pipeline ‡∏ú‡∏¥‡∏î
‚ùå PipelineConnectError: No component named 'invalid_component'

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠ component
pipeline.add_component("correct_name", component)
pipeline.connect("correct_name.output", "next_component.input")
```

#### 4. Component Input/Output Mismatch
```python
# ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: Type mismatch
‚ùå ComponentError: Expected 'str' but got 'list'

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö input/output types
@component.output_types(result=str)  # ‡∏£‡∏∞‡∏ö‡∏∏ type ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
def run(self, input_data: str) -> dict:  # ‡πÉ‡∏ä‡πâ type hints
    return {"result": str(input_data)}
```

### üîç Debugging Tips

#### 1. Enable Detailed Logging
```python
import logging

# ‡πÄ‡∏õ‡∏¥‡∏î debug logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger("haystack")
logger.setLevel(logging.DEBUG)
```

#### 2. Pipeline Visualization
```python
# ‡∏î‡∏π pipeline structure
pipeline.show()  # ‡πÅ‡∏™‡∏î‡∏á graph
print(pipeline.get_component_names())  # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ components
```

#### 3. Step-by-step Debugging
```python
# ‡∏£‡∏±‡∏ô component ‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß
component_result = component.run(**inputs)
print(f"Component output: {component_result}")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö intermediate results
result = pipeline.run(inputs, include_outputs_from=["component1", "component2"])
```

### üìö Resources ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠

1. **Official Documentation**: https://docs.haystack.deepset.ai/
2. **GitHub Issues**: https://github.com/deepset-ai/haystack/issues
3. **Discord Community**: https://discord.com/invite/VBpFzsgRVF
4. **Stack Overflow**: Tag `haystack`
5. **Examples**: https://haystack.deepset.ai/tutorials

### ‚ö° Performance Tips

```python
# 1. ‡πÉ‡∏ä‡πâ batch processing
documents = [doc1, doc2, doc3, ...]  # ‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô batch

# 2. ‡πÉ‡∏ä‡πâ async ‡∏™‡∏≥‡∏´‡∏£ÔøΩr‡∏á‡∏≤‡∏ô I/O intensive
async def process_many_queries(queries):
    tasks = [pipeline.run_async({"query": q}) for q in queries]
    return await asyncio.gather(*tasks)

# 3. ‡πÉ‡∏ä‡πâ caching
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_embedding(text):
    return generate_embedding(text)

# 4. ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á batch sizes
splitter = DocumentSplitter(split_length=100)  # ‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á = ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
```

---

## üéâ ‡∏™‡∏£‡∏∏‡∏õ

Haystack ‡πÄ‡∏õ‡πá‡∏ô framework ‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô AI ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡∏î‡πâ‡∏ß‡∏¢‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏Ç‡∏≠‡∏á **Components** ‡πÅ‡∏•‡∏∞ **Pipelines** ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:

‚úÖ **‡∏™‡∏£‡πâ‡∏≤‡∏á RAG systems** ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô  
‚úÖ **‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö LLMs** ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß  
‚úÖ **‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• documents** ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û  
‚úÖ **‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞ debug** ‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢  
‚úÖ **Scale** ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£  

### üöÄ Next Steps
1. ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå `basic_example.py` ‡πÅ‡∏•‡∏∞ `advanced_example.py`
2. ‡∏™‡∏£‡πâ‡∏≤‡∏á custom component ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
3. ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ LLM providers ‡∏ï‡πà‡∏≤‡∏á‡πÜ
4. ‡∏™‡∏£‡πâ‡∏≤‡∏á RAG system ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
5. ‡∏®‡∏∂‡∏Å‡∏©‡∏≤ advanced features ‡πÄ‡∏ä‡πà‡∏ô agents ‡πÅ‡∏•‡∏∞ tools

---

**Happy Building with Haystack! üèóÔ∏èü§ñ**